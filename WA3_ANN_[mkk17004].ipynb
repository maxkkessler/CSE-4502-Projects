{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "WA3_ANN_[mkk17004].ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/maxkkessler/CSE-4502-Projects/blob/main/WA3_ANN_%5Bmkk17004%5D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SMRu7Awzgex8"
      },
      "source": [
        "Starter code for Artificial Neural Network assignment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "Yli1d1ltgSKf",
        "outputId": "32ae516d-cdce-403a-e746-98d8973e8e8f"
      },
      "source": [
        "# Load the libaries dataset\n",
        "# When you load the datasets, please select both training and testing files at \"Choose Files\" and click \"Open\"\n",
        "# You could add other necessary libraries here\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from google.colab import files\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
        "# If you would like to delete the files uploaded, go to Runtime --> Factory reset runtime\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-8f015ab1-ad17-4292-b75f-98ca9634b28b\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-8f015ab1-ad17-4292-b75f-98ca9634b28b\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving validation_data_new_7dim.csv to validation_data_new_7dim.csv\n",
            "Saving training_data_new_7dim.csv to training_data_new_7dim.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZVboAvog_9N"
      },
      "source": [
        "# Read the corresponding csv files\n",
        "train_set = pd.read_csv(\"training_data_new_7dim.csv\") \n",
        "valid_set = pd.read_csv(\"validation_data_new_7dim.csv\") \n",
        "\n",
        "# You can try standard scaler instead if you want\n",
        "min_max_scaler = preprocessing.MinMaxScaler()\n",
        "train_set = min_max_scaler.fit_transform(train_set)\n",
        "valid_set = min_max_scaler.fit_transform(valid_set)\n",
        "train_set = pd.DataFrame(train_set)\n",
        "valid_set = pd.DataFrame(valid_set)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6tWgYz6hJEh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        },
        "outputId": "cc8c3e37-6a00-44c5-8803-34c7bd47ebf8"
      },
      "source": [
        "# Preview the processed training data\n",
        "train_set"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.156250</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.416667</td>\n",
              "      <td>0.153846</td>\n",
              "      <td>0.545455</td>\n",
              "      <td>0.416667</td>\n",
              "      <td>0.419355</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.093750</td>\n",
              "      <td>0.629630</td>\n",
              "      <td>0.416667</td>\n",
              "      <td>0.169231</td>\n",
              "      <td>0.545455</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.290323</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.171875</td>\n",
              "      <td>0.518519</td>\n",
              "      <td>0.458333</td>\n",
              "      <td>0.138462</td>\n",
              "      <td>0.393939</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.322581</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.203125</td>\n",
              "      <td>0.518519</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>0.215385</td>\n",
              "      <td>0.363636</td>\n",
              "      <td>0.194444</td>\n",
              "      <td>0.451613</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.171875</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.458333</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.363636</td>\n",
              "      <td>0.444444</td>\n",
              "      <td>0.225806</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>795</th>\n",
              "      <td>0.531250</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.492308</td>\n",
              "      <td>0.606061</td>\n",
              "      <td>0.555556</td>\n",
              "      <td>0.483871</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>796</th>\n",
              "      <td>0.546875</td>\n",
              "      <td>0.592593</td>\n",
              "      <td>0.708333</td>\n",
              "      <td>0.569231</td>\n",
              "      <td>0.818182</td>\n",
              "      <td>0.722222</td>\n",
              "      <td>0.548387</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>797</th>\n",
              "      <td>0.578125</td>\n",
              "      <td>0.740741</td>\n",
              "      <td>0.708333</td>\n",
              "      <td>0.538462</td>\n",
              "      <td>0.757576</td>\n",
              "      <td>0.694444</td>\n",
              "      <td>0.516129</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>798</th>\n",
              "      <td>0.546875</td>\n",
              "      <td>0.814815</td>\n",
              "      <td>0.875000</td>\n",
              "      <td>0.569231</td>\n",
              "      <td>0.848485</td>\n",
              "      <td>0.611111</td>\n",
              "      <td>0.741935</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>799</th>\n",
              "      <td>0.515625</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.875000</td>\n",
              "      <td>0.507692</td>\n",
              "      <td>0.696970</td>\n",
              "      <td>0.555556</td>\n",
              "      <td>0.580645</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>800 rows × 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            0         1         2         3         4         5         6    7\n",
              "0    0.156250  0.666667  0.416667  0.153846  0.545455  0.416667  0.419355  1.0\n",
              "1    0.093750  0.629630  0.416667  0.169231  0.545455  0.333333  0.290323  1.0\n",
              "2    0.171875  0.518519  0.458333  0.138462  0.393939  0.333333  0.322581  1.0\n",
              "3    0.203125  0.518519  0.125000  0.215385  0.363636  0.194444  0.451613  1.0\n",
              "4    0.171875  0.333333  0.458333  0.200000  0.363636  0.444444  0.225806  1.0\n",
              "..        ...       ...       ...       ...       ...       ...       ...  ...\n",
              "795  0.531250  0.666667  0.750000  0.492308  0.606061  0.555556  0.483871  0.0\n",
              "796  0.546875  0.592593  0.708333  0.569231  0.818182  0.722222  0.548387  0.0\n",
              "797  0.578125  0.740741  0.708333  0.538462  0.757576  0.694444  0.516129  0.0\n",
              "798  0.546875  0.814815  0.875000  0.569231  0.848485  0.611111  0.741935  0.0\n",
              "799  0.515625  0.666667  0.875000  0.507692  0.696970  0.555556  0.580645  0.0\n",
              "\n",
              "[800 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5U62XZIhRBx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        },
        "outputId": "409352c0-f301-499b-e6cc-b51087d92144"
      },
      "source": [
        "# Preview the processed validation data\n",
        "valid_set"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.169492</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.629630</td>\n",
              "      <td>0.220339</td>\n",
              "      <td>0.555556</td>\n",
              "      <td>0.533333</td>\n",
              "      <td>0.50000</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.135593</td>\n",
              "      <td>0.708333</td>\n",
              "      <td>0.407407</td>\n",
              "      <td>0.220339</td>\n",
              "      <td>0.629630</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.43750</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.118644</td>\n",
              "      <td>0.791667</td>\n",
              "      <td>0.592593</td>\n",
              "      <td>0.288136</td>\n",
              "      <td>0.703704</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.43750</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.118644</td>\n",
              "      <td>0.791667</td>\n",
              "      <td>0.555556</td>\n",
              "      <td>0.237288</td>\n",
              "      <td>0.629630</td>\n",
              "      <td>0.433333</td>\n",
              "      <td>0.28125</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.067797</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.370370</td>\n",
              "      <td>0.237288</td>\n",
              "      <td>0.629630</td>\n",
              "      <td>0.466667</td>\n",
              "      <td>0.28125</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>195</th>\n",
              "      <td>0.389831</td>\n",
              "      <td>0.416667</td>\n",
              "      <td>0.629630</td>\n",
              "      <td>0.491525</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.300000</td>\n",
              "      <td>0.46875</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>196</th>\n",
              "      <td>0.338983</td>\n",
              "      <td>0.583333</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.508475</td>\n",
              "      <td>0.814815</td>\n",
              "      <td>0.266667</td>\n",
              "      <td>0.59375</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>197</th>\n",
              "      <td>0.372881</td>\n",
              "      <td>0.541667</td>\n",
              "      <td>0.629630</td>\n",
              "      <td>0.474576</td>\n",
              "      <td>0.777778</td>\n",
              "      <td>0.233333</td>\n",
              "      <td>0.62500</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>198</th>\n",
              "      <td>0.406780</td>\n",
              "      <td>0.541667</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.559322</td>\n",
              "      <td>0.740741</td>\n",
              "      <td>0.266667</td>\n",
              "      <td>0.59375</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199</th>\n",
              "      <td>0.423729</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.703704</td>\n",
              "      <td>0.525424</td>\n",
              "      <td>0.592593</td>\n",
              "      <td>0.233333</td>\n",
              "      <td>0.59375</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>200 rows × 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            0         1         2         3         4         5        6    7\n",
              "0    0.169492  0.666667  0.629630  0.220339  0.555556  0.533333  0.50000  1.0\n",
              "1    0.135593  0.708333  0.407407  0.220339  0.629630  0.500000  0.43750  1.0\n",
              "2    0.118644  0.791667  0.592593  0.288136  0.703704  0.500000  0.43750  1.0\n",
              "3    0.118644  0.791667  0.555556  0.237288  0.629630  0.433333  0.28125  1.0\n",
              "4    0.067797  0.750000  0.370370  0.237288  0.629630  0.466667  0.28125  1.0\n",
              "..        ...       ...       ...       ...       ...       ...      ...  ...\n",
              "195  0.389831  0.416667  0.629630  0.491525  0.000000  0.300000  0.46875  0.0\n",
              "196  0.338983  0.583333  0.666667  0.508475  0.814815  0.266667  0.59375  0.0\n",
              "197  0.372881  0.541667  0.629630  0.474576  0.777778  0.233333  0.62500  0.0\n",
              "198  0.406780  0.541667  0.666667  0.559322  0.740741  0.266667  0.59375  0.0\n",
              "199  0.423729  0.500000  0.703704  0.525424  0.592593  0.233333  0.59375  0.0\n",
              "\n",
              "[200 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jlqeEDYihYLK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ab42be5-cd6d-4243-b4e7-ffe717fea768"
      },
      "source": [
        "train_x,train_y=train_set.iloc[:,0:7],train_set.iloc[:,7]\n",
        "valid_x,valid_y=valid_set.iloc[:,0:7],valid_set.iloc[:,7]\n",
        "\n",
        "# Training data\n",
        "train_x=train_x.to_numpy()\n",
        "train_y=train_y.to_numpy()\n",
        "valid_x=valid_x.to_numpy()\n",
        "valid_y=valid_y.to_numpy()\n",
        "\n",
        "print(valid_x)\n",
        "print(valid_y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.16949153 0.66666667 0.62962963 ... 0.55555556 0.53333333 0.5       ]\n",
            " [0.13559322 0.70833333 0.40740741 ... 0.62962963 0.5        0.4375    ]\n",
            " [0.11864407 0.79166667 0.59259259 ... 0.7037037  0.5        0.4375    ]\n",
            " ...\n",
            " [0.37288136 0.54166667 0.62962963 ... 0.77777778 0.23333333 0.625     ]\n",
            " [0.40677966 0.54166667 0.66666667 ... 0.74074074 0.26666667 0.59375   ]\n",
            " [0.42372881 0.5        0.7037037  ... 0.59259259 0.23333333 0.59375   ]]\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YmMY3QTDhnro"
      },
      "source": [
        "**Question 2(a)** (10 marks)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rgm1GEzBhqDt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c22dc322-a6c8-472b-fc25-b562a059101d"
      },
      "source": [
        "# Your codes go from here\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras import models\n",
        "from keras import layers\n",
        "from keras import optimizers\n",
        "from keras import losses\n",
        "from keras import metrics\n",
        "\n",
        "\n",
        "#take some of the data to test on\n",
        "train_x, test_x, train_y, test_y = train_test_split(train_x, train_y, test_size=0.3,random_state=109)\n",
        "\n",
        "#make our model\n",
        "model = models.Sequential()\n",
        "model.add(layers.Dense(32, activation='relu', input_shape= (None, 7)))\n",
        "model.add(layers.Dense(32, activation='relu'))#Add code here. This is the second layer with 16 nodes and  activation function relu.\n",
        "model.add(layers.Dense(1, activation='sigmoid')) #Add code here. This is the Third layer with 1 nodes and  activation function sigmoid.\n",
        "\n",
        "#optimize the model with adam. I dont know why I just choose adam\n",
        "model.compile(optimizer='adam',\n",
        "                loss='binary_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "#fit the model\n",
        "history = model.fit(train_x,\n",
        "                    train_y,\n",
        "                    epochs=16,\n",
        "                    batch_size=124,\n",
        "                    validation_data=(valid_x, valid_y))\n",
        "\n",
        "\n",
        "_, accuracy = model.evaluate(test_x, test_y)\n",
        "print(\"Accuracy is: {} \\n\\n\\n\".format(accuracy))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/16\n",
            "WARNING:tensorflow:Model was constructed with shape (None, None, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 7), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
            "WARNING:tensorflow:Model was constructed with shape (None, None, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 7), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
            "1/5 [=====>........................] - ETA: 2s - loss: 0.6663 - accuracy: 0.9355WARNING:tensorflow:Model was constructed with shape (None, None, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 7), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
            "5/5 [==============================] - 1s 103ms/step - loss: 0.6638 - accuracy: 0.9011 - val_loss: 0.6539 - val_accuracy: 0.8350\n",
            "Epoch 2/16\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.6476 - accuracy: 0.7915 - val_loss: 0.6403 - val_accuracy: 0.6650\n",
            "Epoch 3/16\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.6365 - accuracy: 0.6813 - val_loss: 0.6282 - val_accuracy: 0.6450\n",
            "Epoch 4/16\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.6286 - accuracy: 0.6500 - val_loss: 0.6160 - val_accuracy: 0.6600\n",
            "Epoch 5/16\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.6180 - accuracy: 0.6978 - val_loss: 0.6032 - val_accuracy: 0.7300\n",
            "Epoch 6/16\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.6007 - accuracy: 0.7853 - val_loss: 0.5881 - val_accuracy: 0.8400\n",
            "Epoch 7/16\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.5806 - accuracy: 0.8625 - val_loss: 0.5694 - val_accuracy: 0.9350\n",
            "Epoch 8/16\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.5702 - accuracy: 0.9455 - val_loss: 0.5484 - val_accuracy: 0.9950\n",
            "Epoch 9/16\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.5503 - accuracy: 0.9872 - val_loss: 0.5272 - val_accuracy: 0.9950\n",
            "Epoch 10/16\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.5235 - accuracy: 0.9966 - val_loss: 0.5033 - val_accuracy: 0.9950\n",
            "Epoch 11/16\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.5030 - accuracy: 1.0000 - val_loss: 0.4773 - val_accuracy: 0.9950\n",
            "Epoch 12/16\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.4788 - accuracy: 1.0000 - val_loss: 0.4493 - val_accuracy: 0.9900\n",
            "Epoch 13/16\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.4500 - accuracy: 1.0000 - val_loss: 0.4187 - val_accuracy: 0.9900\n",
            "Epoch 14/16\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.4224 - accuracy: 1.0000 - val_loss: 0.3843 - val_accuracy: 0.9900\n",
            "Epoch 15/16\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3907 - accuracy: 1.0000 - val_loss: 0.3490 - val_accuracy: 0.9950\n",
            "Epoch 16/16\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3530 - accuracy: 1.0000 - val_loss: 0.3158 - val_accuracy: 0.9950\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3305 - accuracy: 1.0000\n",
            "Accuracy is: 1.0 \n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ODQuQu7mFNf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G-KyusLXhwHX"
      },
      "source": [
        "**Question 2(b)** (5 marks)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NyZJ2yyDhydB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2829
        },
        "outputId": "19359a7a-0b75-4708-a48c-5caf9d22aff4"
      },
      "source": [
        "# Your codes go from here\n",
        "r = [.1, .01, .001, .0001]\n",
        "string_r = [\"r = .1\", \"r = .01\", \"r = .001\", \"r = .0001\"]\n",
        "accuracy = []\n",
        "train_x, test_x, train_y, test_y = train_test_split(train_x, train_y, test_size=0.3,random_state=109)\n",
        "\n",
        "for rate in r:\n",
        "  #take some of the data to test on\n",
        "\n",
        "  #make our model\n",
        "  model = models.Sequential()\n",
        "  model.add(layers.Dense(32, activation='relu', input_shape= (None, 7)))\n",
        "  model.add(layers.Dense(32, activation='relu'))#Add code here. This is the second layer with 16 nodes and  activation function relu.\n",
        "  model.add(layers.Dense(1, activation='sigmoid')) #Add code here. This is the Third layer with 1 nodes and  activation function sigmoid.\n",
        "\n",
        "  #optimize the model with adam. I dont know why I just choose adam\n",
        "  model.compile(optimizer=optimizers.RMSprop(lr=rate),\n",
        "              loss=losses.binary_crossentropy,\n",
        "              metrics=[metrics.binary_accuracy])\n",
        "  \n",
        "  #fit the model\n",
        "  history = model.fit(train_x,\n",
        "                      train_y,\n",
        "                      epochs=16,\n",
        "                      batch_size=124,\n",
        "                      validation_data=(valid_x, valid_y))\n",
        "\n",
        "\n",
        "  _, a = model.evaluate(test_x, test_y)\n",
        "  accuracy.append(a)\n",
        "  \n",
        "\n",
        "fig = plt.figure()\n",
        "ax = fig.add_axes([0,0,1,1])\n",
        "ax.bar(string_r,accuracy)\n",
        "ax.set_title(\"Accuracy vs. Learning Rate\")\n",
        "ax.set_ylabel(\"Accuracy\")\n",
        "plt.show()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/16\n",
            "WARNING:tensorflow:Model was constructed with shape (None, None, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 7), dtype=tf.float32, name='dense_18_input'), name='dense_18_input', description=\"created by layer 'dense_18_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
            "WARNING:tensorflow:Model was constructed with shape (None, None, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 7), dtype=tf.float32, name='dense_18_input'), name='dense_18_input', description=\"created by layer 'dense_18_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.7103 - binary_accuracy: 0.1532WARNING:tensorflow:Model was constructed with shape (None, None, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 7), dtype=tf.float32, name='dense_18_input'), name='dense_18_input', description=\"created by layer 'dense_18_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
            "2/2 [==============================] - 1s 202ms/step - loss: 2.1302 - binary_accuracy: 0.2396 - val_loss: 8.4990 - val_binary_accuracy: 0.5000\n",
            "Epoch 2/16\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 6.7348 - binary_accuracy: 0.5025 - val_loss: 0.6786 - val_binary_accuracy: 0.5000\n",
            "Epoch 3/16\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.7485 - binary_accuracy: 0.4464 - val_loss: 0.7578 - val_binary_accuracy: 0.5000\n",
            "Epoch 4/16\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.6895 - binary_accuracy: 0.5385 - val_loss: 0.5663 - val_binary_accuracy: 0.7700\n",
            "Epoch 5/16\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.5381 - binary_accuracy: 0.7722 - val_loss: 0.4626 - val_binary_accuracy: 0.7950\n",
            "Epoch 6/16\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.5755 - binary_accuracy: 0.6855 - val_loss: 0.4732 - val_binary_accuracy: 0.9700\n",
            "Epoch 7/16\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.4458 - binary_accuracy: 1.0000 - val_loss: 0.3102 - val_binary_accuracy: 0.9850\n",
            "Epoch 8/16\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.3508 - binary_accuracy: 0.8923 - val_loss: 1.3247 - val_binary_accuracy: 0.5100\n",
            "Epoch 9/16\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 1.3665 - binary_accuracy: 0.4569 - val_loss: 0.3479 - val_binary_accuracy: 0.9700\n",
            "Epoch 10/16\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.3280 - binary_accuracy: 1.0000 - val_loss: 0.2529 - val_binary_accuracy: 0.9100\n",
            "Epoch 11/16\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.4087 - binary_accuracy: 0.7559 - val_loss: 0.2420 - val_binary_accuracy: 1.0000\n",
            "Epoch 12/16\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.2417 - binary_accuracy: 1.0000 - val_loss: 0.1273 - val_binary_accuracy: 1.0000\n",
            "Epoch 13/16\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 0.1293 - binary_accuracy: 0.9938 - val_loss: 0.0737 - val_binary_accuracy: 1.0000\n",
            "Epoch 14/16\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.0595 - binary_accuracy: 1.0000 - val_loss: 0.0559 - val_binary_accuracy: 1.0000\n",
            "Epoch 15/16\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.0438 - binary_accuracy: 1.0000 - val_loss: 0.0290 - val_binary_accuracy: 1.0000\n",
            "Epoch 16/16\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.0386 - binary_accuracy: 1.0000 - val_loss: 0.0241 - val_binary_accuracy: 1.0000\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0149 - binary_accuracy: 1.0000\n",
            "Epoch 1/16\n",
            "WARNING:tensorflow:Model was constructed with shape (None, None, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 7), dtype=tf.float32, name='dense_21_input'), name='dense_21_input', description=\"created by layer 'dense_21_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
            "WARNING:tensorflow:Model was constructed with shape (None, None, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 7), dtype=tf.float32, name='dense_21_input'), name='dense_21_input', description=\"created by layer 'dense_21_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.6990 - binary_accuracy: 0.5161WARNING:tensorflow:Model was constructed with shape (None, None, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 7), dtype=tf.float32, name='dense_21_input'), name='dense_21_input', description=\"created by layer 'dense_21_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
            "2/2 [==============================] - 1s 181ms/step - loss: 0.6783 - binary_accuracy: 0.5316 - val_loss: 0.5719 - val_binary_accuracy: 0.8800\n",
            "Epoch 2/16\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 0.5881 - binary_accuracy: 0.6933 - val_loss: 0.5136 - val_binary_accuracy: 0.9950\n",
            "Epoch 3/16\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.4856 - binary_accuracy: 0.9366 - val_loss: 0.4510 - val_binary_accuracy: 0.7350\n",
            "Epoch 4/16\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.3659 - binary_accuracy: 0.9382 - val_loss: 0.2928 - val_binary_accuracy: 0.9950\n",
            "Epoch 5/16\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.2798 - binary_accuracy: 0.9597 - val_loss: 0.3068 - val_binary_accuracy: 0.8700\n",
            "Epoch 6/16\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.3610 - binary_accuracy: 0.7905 - val_loss: 0.2029 - val_binary_accuracy: 0.9950\n",
            "Epoch 7/16\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.1878 - binary_accuracy: 0.9938 - val_loss: 0.1724 - val_binary_accuracy: 0.9950\n",
            "Epoch 8/16\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.1540 - binary_accuracy: 0.9938 - val_loss: 0.1429 - val_binary_accuracy: 0.9950\n",
            "Epoch 9/16\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.1294 - binary_accuracy: 0.9876 - val_loss: 0.1342 - val_binary_accuracy: 0.9900\n",
            "Epoch 10/16\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.1034 - binary_accuracy: 0.9930 - val_loss: 0.2131 - val_binary_accuracy: 0.9200\n",
            "Epoch 11/16\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.1293 - binary_accuracy: 0.9807 - val_loss: 0.2352 - val_binary_accuracy: 0.8850\n",
            "Epoch 12/16\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.1344 - binary_accuracy: 0.9613 - val_loss: 0.1990 - val_binary_accuracy: 0.9150\n",
            "Epoch 13/16\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.1009 - binary_accuracy: 0.9938 - val_loss: 0.1068 - val_binary_accuracy: 0.9750\n",
            "Epoch 14/16\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.0711 - binary_accuracy: 0.9965 - val_loss: 0.1460 - val_binary_accuracy: 0.9450\n",
            "Epoch 15/16\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.0818 - binary_accuracy: 0.9938 - val_loss: 0.0678 - val_binary_accuracy: 1.0000\n",
            "Epoch 16/16\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.0473 - binary_accuracy: 1.0000 - val_loss: 0.0421 - val_binary_accuracy: 1.0000\n",
            "3/3 [==============================] - 0s 2ms/step - loss: 0.0272 - binary_accuracy: 1.0000\n",
            "Epoch 1/16\n",
            "WARNING:tensorflow:Model was constructed with shape (None, None, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 7), dtype=tf.float32, name='dense_24_input'), name='dense_24_input', description=\"created by layer 'dense_24_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
            "WARNING:tensorflow:Model was constructed with shape (None, None, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 7), dtype=tf.float32, name='dense_24_input'), name='dense_24_input', description=\"created by layer 'dense_24_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.7172 - binary_accuracy: 0.5081WARNING:tensorflow:Model was constructed with shape (None, None, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 7), dtype=tf.float32, name='dense_24_input'), name='dense_24_input', description=\"created by layer 'dense_24_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
            "2/2 [==============================] - 1s 184ms/step - loss: 0.7128 - binary_accuracy: 0.4975 - val_loss: 0.6876 - val_binary_accuracy: 0.6100\n",
            "Epoch 2/16\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.6850 - binary_accuracy: 0.7220 - val_loss: 0.6743 - val_binary_accuracy: 0.5450\n",
            "Epoch 3/16\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.6691 - binary_accuracy: 0.8018 - val_loss: 0.6625 - val_binary_accuracy: 0.6000\n",
            "Epoch 4/16\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.6537 - binary_accuracy: 0.8829 - val_loss: 0.6517 - val_binary_accuracy: 0.6100\n",
            "Epoch 5/16\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.6420 - binary_accuracy: 0.9181 - val_loss: 0.6426 - val_binary_accuracy: 0.6300\n",
            "Epoch 6/16\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.6306 - binary_accuracy: 0.9068 - val_loss: 0.6343 - val_binary_accuracy: 0.7000\n",
            "Epoch 7/16\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.6226 - binary_accuracy: 0.9296 - val_loss: 0.6266 - val_binary_accuracy: 0.7500\n",
            "Epoch 8/16\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.6138 - binary_accuracy: 0.9517 - val_loss: 0.6190 - val_binary_accuracy: 0.7850\n",
            "Epoch 9/16\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.6070 - binary_accuracy: 0.9586 - val_loss: 0.6110 - val_binary_accuracy: 0.7850\n",
            "Epoch 10/16\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.5979 - binary_accuracy: 0.9648 - val_loss: 0.6033 - val_binary_accuracy: 0.7550\n",
            "Epoch 11/16\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.5889 - binary_accuracy: 0.9339 - val_loss: 0.5947 - val_binary_accuracy: 0.8100\n",
            "Epoch 12/16\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.5788 - binary_accuracy: 0.9710 - val_loss: 0.5863 - val_binary_accuracy: 0.8100\n",
            "Epoch 13/16\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.5687 - binary_accuracy: 0.9640 - val_loss: 0.5771 - val_binary_accuracy: 0.8550\n",
            "Epoch 14/16\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.5615 - binary_accuracy: 0.9842 - val_loss: 0.5682 - val_binary_accuracy: 0.8550\n",
            "Epoch 15/16\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.5498 - binary_accuracy: 0.9903 - val_loss: 0.5588 - val_binary_accuracy: 0.8950\n",
            "Epoch 16/16\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.5419 - binary_accuracy: 0.9876 - val_loss: 0.5504 - val_binary_accuracy: 0.8600\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 0.5452 - binary_accuracy: 0.9880\n",
            "Epoch 1/16\n",
            "WARNING:tensorflow:Model was constructed with shape (None, None, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 7), dtype=tf.float32, name='dense_27_input'), name='dense_27_input', description=\"created by layer 'dense_27_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
            "WARNING:tensorflow:Model was constructed with shape (None, None, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 7), dtype=tf.float32, name='dense_27_input'), name='dense_27_input', description=\"created by layer 'dense_27_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.7407 - binary_accuracy: 0.5000WARNING:tensorflow:Model was constructed with shape (None, None, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 7), dtype=tf.float32, name='dense_27_input'), name='dense_27_input', description=\"created by layer 'dense_27_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
            "2/2 [==============================] - 1s 187ms/step - loss: 0.7423 - binary_accuracy: 0.4948 - val_loss: 0.7450 - val_binary_accuracy: 0.5000\n",
            "Epoch 2/16\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.7432 - binary_accuracy: 0.4813 - val_loss: 0.7434 - val_binary_accuracy: 0.5000\n",
            "Epoch 3/16\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 0.7375 - binary_accuracy: 0.5001 - val_loss: 0.7419 - val_binary_accuracy: 0.5000\n",
            "Epoch 4/16\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.7366 - binary_accuracy: 0.4948 - val_loss: 0.7406 - val_binary_accuracy: 0.5000\n",
            "Epoch 5/16\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.7354 - binary_accuracy: 0.4948 - val_loss: 0.7394 - val_binary_accuracy: 0.5000\n",
            "Epoch 6/16\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.7346 - binary_accuracy: 0.4921 - val_loss: 0.7383 - val_binary_accuracy: 0.5000\n",
            "Epoch 7/16\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.7349 - binary_accuracy: 0.4867 - val_loss: 0.7373 - val_binary_accuracy: 0.5000\n",
            "Epoch 8/16\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 0.7350 - binary_accuracy: 0.4786 - val_loss: 0.7363 - val_binary_accuracy: 0.5000\n",
            "Epoch 9/16\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.7326 - binary_accuracy: 0.4867 - val_loss: 0.7353 - val_binary_accuracy: 0.5000\n",
            "Epoch 10/16\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.7299 - binary_accuracy: 0.4975 - val_loss: 0.7343 - val_binary_accuracy: 0.5000\n",
            "Epoch 11/16\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.7266 - binary_accuracy: 0.5082 - val_loss: 0.7333 - val_binary_accuracy: 0.5000\n",
            "Epoch 12/16\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.7272 - binary_accuracy: 0.5001 - val_loss: 0.7323 - val_binary_accuracy: 0.5000\n",
            "Epoch 13/16\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.7272 - binary_accuracy: 0.4975 - val_loss: 0.7314 - val_binary_accuracy: 0.5000\n",
            "Epoch 14/16\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 0.7240 - binary_accuracy: 0.5055 - val_loss: 0.7304 - val_binary_accuracy: 0.5000\n",
            "Epoch 15/16\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.7287 - binary_accuracy: 0.4759 - val_loss: 0.7296 - val_binary_accuracy: 0.5000\n",
            "Epoch 16/16\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.7244 - binary_accuracy: 0.4948 - val_loss: 0.7287 - val_binary_accuracy: 0.5000\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 0.7033 - binary_accuracy: 0.6265\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y1YmNCpAh2JG"
      },
      "source": [
        "**Question 2(c)** (10 marks)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ES2dkIlch34v",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2029
        },
        "outputId": "2cc04b43-0a2d-4931-bdf2-17eb67b773ab"
      },
      "source": [
        "# Your codes go from here\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "#take some of the data to test on\n",
        "train_x, test_x, train_y, test_y = train_test_split(train_x, train_y, test_size=0.3,random_state=109)\n",
        "\n",
        "#make our model\n",
        "model = models.Sequential()\n",
        "model.add(layers.Dense(32, activation='relu', input_shape= (None, 7)))\n",
        "model.add(layers.Dense(32, activation='relu'))#Add code here. This is the second layer with 16 nodes and  activation function relu.\n",
        "model.add(layers.Dense(1, activation='sigmoid')) #Add code here. This is the Third layer with 1 nodes and  activation function sigmoid.\n",
        "\n",
        "#optimize the model with adam. I dont know why I just choose adam\n",
        "model.compile(optimizer='adam',\n",
        "                loss='binary_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "#fit the model\n",
        "history = model.fit(train_x,\n",
        "                    train_y,\n",
        "                    epochs=32,\n",
        "                    batch_size=124,\n",
        "                    validation_data=(valid_x, valid_y))\n",
        "\n",
        "accuracy = []\n",
        "precision = []\n",
        "recall = []\n",
        "f1 = []\n",
        "\n",
        "for e in range(5):\n",
        "  history = model.fit(train_x, train_y, epochs=1, batch_size=124)\n",
        "  pred = model.predict_classes(test_x)\n",
        "  pred = pred[:, 0]\n",
        "  accuracy.append(accuracy_score(test_y, pred))\n",
        "  precision.append(precision_score(test_y, pred))\n",
        "  recall.append(recall_score(test_y, pred))\n",
        "  f1.append(f1_score(test_y, pred))\n",
        "\n",
        "\n",
        "iterations = [\"1\", \"2\", \"3\", \"4\", \"5\"]\n",
        "plt.figure(1, figsize=(18, 12))\n",
        "\n",
        "plt.subplot(221)\n",
        "plt.bar(iterations,accuracy)\n",
        "plt.title(\"Accuracy vs. Iterations\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.xlabel(\"Iterations\")\n",
        "\n",
        "plt.subplot(222)\n",
        "plt.bar(iterations,precision)\n",
        "plt.title(\"Precision vs. Iterations\")\n",
        "plt.ylabel(\"Precision\")\n",
        "plt.xlabel(\"Iterations\")\n",
        "\n",
        "plt.subplot(223)\n",
        "plt.bar(iterations,recall)\n",
        "plt.title(\"Recall vs. Iterations\")\n",
        "plt.ylabel(\"Recall\")\n",
        "plt.xlabel(\"Iterations\")\n",
        "\n",
        "plt.subplot(224)\n",
        "plt.bar(iterations,f1)\n",
        "plt.title(\"F1 vs. Iterations\")\n",
        "plt.ylabel(\"F1-measure\")\n",
        "plt.xlabel(\"Iterations\")\n",
        "\n",
        "\n",
        "plt.show()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/32\n",
            "WARNING:tensorflow:Model was constructed with shape (None, None, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 7), dtype=tf.float32, name='dense_54_input'), name='dense_54_input', description=\"created by layer 'dense_54_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
            "WARNING:tensorflow:Model was constructed with shape (None, None, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 7), dtype=tf.float32, name='dense_54_input'), name='dense_54_input', description=\"created by layer 'dense_54_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.7214 - accuracy: 0.3333WARNING:tensorflow:Model was constructed with shape (None, None, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 7), dtype=tf.float32, name='dense_54_input'), name='dense_54_input', description=\"created by layer 'dense_54_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
            "1/1 [==============================] - 1s 651ms/step - loss: 0.7214 - accuracy: 0.3333 - val_loss: 0.6646 - val_accuracy: 0.5000\n",
            "Epoch 2/32\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.7168 - accuracy: 0.3333 - val_loss: 0.6641 - val_accuracy: 0.5000\n",
            "Epoch 3/32\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.7124 - accuracy: 0.3333 - val_loss: 0.6637 - val_accuracy: 0.5000\n",
            "Epoch 4/32\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.7083 - accuracy: 0.3333 - val_loss: 0.6634 - val_accuracy: 0.5000\n",
            "Epoch 5/32\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.7044 - accuracy: 0.3333 - val_loss: 0.6634 - val_accuracy: 0.5000\n",
            "Epoch 6/32\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.7005 - accuracy: 0.3333 - val_loss: 0.6634 - val_accuracy: 0.5050\n",
            "Epoch 7/32\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.6968 - accuracy: 0.3333 - val_loss: 0.6636 - val_accuracy: 0.5100\n",
            "Epoch 8/32\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.6933 - accuracy: 0.3333 - val_loss: 0.6639 - val_accuracy: 0.5500\n",
            "Epoch 9/32\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.6899 - accuracy: 0.3333 - val_loss: 0.6644 - val_accuracy: 0.6100\n",
            "Epoch 10/32\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6867 - accuracy: 0.3333 - val_loss: 0.6649 - val_accuracy: 0.6750\n",
            "Epoch 11/32\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.6836 - accuracy: 0.8333 - val_loss: 0.6656 - val_accuracy: 0.8050\n",
            "Epoch 12/32\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.6806 - accuracy: 0.8333 - val_loss: 0.6663 - val_accuracy: 0.9150\n",
            "Epoch 13/32\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.6778 - accuracy: 0.8333 - val_loss: 0.6672 - val_accuracy: 0.9650\n",
            "Epoch 14/32\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.6751 - accuracy: 0.8333 - val_loss: 0.6682 - val_accuracy: 0.9500\n",
            "Epoch 15/32\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.6725 - accuracy: 0.8333 - val_loss: 0.6692 - val_accuracy: 0.8750\n",
            "Epoch 16/32\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.6701 - accuracy: 0.6667 - val_loss: 0.6702 - val_accuracy: 0.7400\n",
            "Epoch 17/32\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.6679 - accuracy: 0.6667 - val_loss: 0.6713 - val_accuracy: 0.6150\n",
            "Epoch 18/32\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.6658 - accuracy: 0.6667 - val_loss: 0.6724 - val_accuracy: 0.5600\n",
            "Epoch 19/32\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6638 - accuracy: 0.6667 - val_loss: 0.6736 - val_accuracy: 0.5300\n",
            "Epoch 20/32\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.6618 - accuracy: 0.6667 - val_loss: 0.6747 - val_accuracy: 0.5150\n",
            "Epoch 21/32\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.6600 - accuracy: 0.6667 - val_loss: 0.6759 - val_accuracy: 0.5050\n",
            "Epoch 22/32\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.6582 - accuracy: 0.6667 - val_loss: 0.6771 - val_accuracy: 0.5000\n",
            "Epoch 23/32\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.6564 - accuracy: 0.6667 - val_loss: 0.6783 - val_accuracy: 0.5000\n",
            "Epoch 24/32\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.6546 - accuracy: 0.6667 - val_loss: 0.6795 - val_accuracy: 0.5000\n",
            "Epoch 25/32\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.6529 - accuracy: 0.6667 - val_loss: 0.6806 - val_accuracy: 0.5000\n",
            "Epoch 26/32\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.6514 - accuracy: 0.6667 - val_loss: 0.6816 - val_accuracy: 0.5000\n",
            "Epoch 27/32\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.6499 - accuracy: 0.6667 - val_loss: 0.6826 - val_accuracy: 0.5000\n",
            "Epoch 28/32\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.6484 - accuracy: 0.6667 - val_loss: 0.6835 - val_accuracy: 0.5000\n",
            "Epoch 29/32\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.6471 - accuracy: 0.6667 - val_loss: 0.6844 - val_accuracy: 0.5000\n",
            "Epoch 30/32\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.6457 - accuracy: 0.6667 - val_loss: 0.6853 - val_accuracy: 0.5000\n",
            "Epoch 31/32\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.6445 - accuracy: 0.6667 - val_loss: 0.6860 - val_accuracy: 0.5000\n",
            "Epoch 32/32\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.6432 - accuracy: 0.6667 - val_loss: 0.6867 - val_accuracy: 0.5000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6420 - accuracy: 0.6667\n",
            "WARNING:tensorflow:Model was constructed with shape (None, None, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 7), dtype=tf.float32, name='dense_54_input'), name='dense_54_input', description=\"created by layer 'dense_54_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6407 - accuracy: 0.6667\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6394 - accuracy: 0.6667\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6382 - accuracy: 0.6667\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6369 - accuracy: 0.6667\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1296x864 with 4 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}